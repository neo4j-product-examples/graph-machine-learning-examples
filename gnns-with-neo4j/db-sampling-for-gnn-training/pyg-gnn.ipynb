{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Graph Sampling for PyG GNN \n",
    "__An example using the [`ogbn-arxiv`](https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv) dataset__\n",
    "\n",
    "![Neo4j version](https://img.shields.io/badge/Neo4j-5-brightgreen)\n",
    "![GDS version](https://img.shields.io/badge/GDS-2.3-brightgreen)\n",
    "![GDS Python Client version](https://img.shields.io/badge/GDS_Python_Client-1.6-brightgreen)\n",
    "\n",
    "This notebook demonstrates how to use [Neo4j Graph Data Science](https://neo4j.com/docs/graph-data-science/current/) and PyTorch Geometric (PyG) to:\n",
    "\n",
    "- Generate a representative sample of a graph database using Graph Data Science [projections](https://neo4j.com/docs/graph-data-science/current/management-ops/projections/graph-project/) and [random walk with restarts sampling algorithm](https://neo4j.com/docs/graph-data-science/current/management-ops/projections/rwr/)\n",
    "- Export the graph sample to Python dataframes\n",
    "- Define and train a Graph Convolutional Neural Network (GCN) on the sample\n",
    "- Evaluate the GCN on a test set\n",
    "\n",
    "## Prerequisites:\n",
    "To generate the Neo4j Graph Database from `ogbn-arxiv`, please first run `db-load.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphdatascience in /opt/conda/lib/python3.7/site-packages (1.6)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.7/site-packages (0.21.1)\n",
      "Requirement already satisfied: multimethod<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (1.9.1)\n",
      "Requirement already satisfied: neo4j<6.0,>=4.4.2 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (5.6.0)\n",
      "Requirement already satisfied: pandas<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (1.3.5)\n",
      "Requirement already satisfied: pyarrow<11.0,>=4.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (7.0.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (4.64.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from neo4j<6.0,>=4.4.2->graphdatascience) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0->graphdatascience) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0->graphdatascience) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas<2.0,>=1.0->graphdatascience) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install graphdatascience python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphdatascience import GraphDataScience\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv('db-credentials.env', override=True)\n",
    "\n",
    "# Use Neo4j URI and credentials according to our setup\n",
    "gds = GraphDataScience(\n",
    "    os.getenv('NEO4J_URI'),\n",
    "    auth=(os.getenv('NEO4J_USERNAME'),\n",
    "          os.getenv('NEO4J_PASSWORD')),\n",
    "    aura_ds=eval(os.getenv('AURA_DS').title()))\n",
    "\n",
    "# Necessary if you enabled Arrow on the db - this is true for AuraDS\n",
    "gds.set_database(\"neo4j\")\n",
    "PROJ_NAME = 'proj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 7474\n",
    "VALID_YEAR = 2018\n",
    "SAMPLE_RATIO = 0.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Neo4j Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gds.graph.exists(PROJ_NAME)['exists']:\n",
    "    gds.graph.get(PROJ_NAME).drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7901cbb0eade4e1387efcebb9667937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:   0%|          | 0/100 [00:00<?, ?%/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 ms, sys: 8.72 ms, total: 37 ms\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g, _ = gds.graph.project(PROJ_NAME, ['Train', 'Valid', 'Test'], ['CITES'], \n",
    "                         nodeProperties =['textEmbedding', 'subjectId', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in our graph: 169,343\n",
      "Number of relationships in our graph: 1,166,243\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nodes in our graph: {g.node_count():,}\")\n",
    "print(f\"Number of relationships in our graph: {g.relationship_count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PROJ_NAME = PROJ_NAME + '_sample'\n",
    "if gds.graph.exists(SAMPLE_PROJ_NAME)['exists']:\n",
    "    gds.graph.get(SAMPLE_PROJ_NAME).drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26eadc8de3f94954bb88b8068148132f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Random walk with restarts sampling:   0%|          | 0/100 [00:00<?, ?%/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 448 ms, sys: 34.4 ms, total: 483 ms\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g_sample, _ = gds.alpha.graph.sample.rwr(SAMPLE_PROJ_NAME, g, samplingRatio=SAMPLE_RATIO,\n",
    "                                         restartProbability=0.05, nodeLabelStratification=True, \n",
    "                                         concurrency=1, randomSeed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in our sample: 57,577\n",
      "Number of relationships in our sample: 459,928\n"
     ]
    }
   ],
   "source": [
    "# If our SAMPLE_RATIO is 0.34 we should have somewhere around 0.34 * 269,343 ~ 55,883 nodes in our sample\n",
    "print(f\"Number of nodes in our sample: {g_sample.node_count():,}\")\n",
    "\n",
    "# And let's see how many relationships we have\n",
    "print(f\"Number of relationships in our sample: {g_sample.relationship_count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree distribution in our full graph:\n",
      "p99      37.000000\n",
      "min       0.000000\n",
      "max     436.000000\n",
      "mean      6.886869\n",
      "p90      18.000000\n",
      "p50       4.000000\n",
      "p999     71.000000\n",
      "p95      24.000000\n",
      "p75       9.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Degree distribution in our sample:\n",
      "p99      40.000000\n",
      "min       0.000000\n",
      "max     403.000000\n",
      "mean      7.988051\n",
      "p90      20.000000\n",
      "p50       5.000000\n",
      "p999     82.000000\n",
      "p95      26.000000\n",
      "p75      11.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We should also see similar degree distributions\n",
    "print(f\"Degree distribution in our full graph:\")\n",
    "print(g.degree_distribution())\n",
    "\n",
    "# And let's see how many relationships we got\n",
    "print(f\"\\n\\nDegree distribution in our sample:\")\n",
    "print(g_sample.degree_distribution())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Sampled Graph to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_topology_df = gds.beta.graph.relationships.stream(g_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_node_df = gds.graph.nodeProperties.stream(\n",
    "    g_sample,\n",
    "    ['subjectId', 'year', 'textEmbedding'],\n",
    "    separate_property_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Index Graph Data for PyG\n",
    "Since we sampled from our Neo4j Graph, we have some missing node ids. This will create issues when trying to transform our data for PyG. To resolve, we will re-assign sequential node ids for the node and relationship topology dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeId</th>\n",
       "      <th>neo4jNodeId</th>\n",
       "      <th>subjectId</th>\n",
       "      <th>year</th>\n",
       "      <th>textEmbedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>52410</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[0.12081799656152725, -0.033817000687122345, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>52413</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.03647800162434578, 0.10607799887657166, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52416</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.020646000280976295, 0.0589819997549057, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>52422</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.14541900157928467, -0.10240700095891953, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52426</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.21182499825954437, 0.02007099986076355, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57572</th>\n",
       "      <td>57572</td>\n",
       "      <td>52393</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.04432599991559982, -0.05412999913096428, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57573</th>\n",
       "      <td>57573</td>\n",
       "      <td>52398</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.17306800186634064, 0.027883000671863556, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57574</th>\n",
       "      <td>57574</td>\n",
       "      <td>52404</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.13642600178718567, -0.03896800056099892, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57575</th>\n",
       "      <td>57575</td>\n",
       "      <td>52405</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.33581000566482544, 0.2053699940443039, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57576</th>\n",
       "      <td>57576</td>\n",
       "      <td>52408</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[0.04785099998116493, 0.07365299761295319, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57577 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nodeId  neo4jNodeId  subjectId  year  \\\n",
       "0           0        52410         24  2019   \n",
       "1           1        52413         24  2019   \n",
       "2           2        52416         24  2019   \n",
       "3           3        52422         24  2019   \n",
       "4           4        52426         24  2019   \n",
       "...       ...          ...        ...   ...   \n",
       "57572   57572        52393         24  2019   \n",
       "57573   57573        52398         24  2019   \n",
       "57574   57574        52404         24  2019   \n",
       "57575   57575        52405         24  2019   \n",
       "57576   57576        52408         24  2019   \n",
       "\n",
       "                                           textEmbedding  \n",
       "0      [0.12081799656152725, -0.033817000687122345, -...  \n",
       "1      [-0.03647800162434578, 0.10607799887657166, -0...  \n",
       "2      [-0.020646000280976295, 0.0589819997549057, -0...  \n",
       "3      [-0.14541900157928467, -0.10240700095891953, -...  \n",
       "4      [-0.21182499825954437, 0.02007099986076355, -0...  \n",
       "...                                                  ...  \n",
       "57572  [-0.04432599991559982, -0.05412999913096428, -...  \n",
       "57573  [-0.17306800186634064, 0.027883000671863556, -...  \n",
       "57574  [-0.13642600178718567, -0.03896800056099892, -...  \n",
       "57575  [-0.33581000566482544, 0.2053699940443039, -0....  \n",
       "57576  [0.04785099998116493, 0.07365299761295319, -0....  \n",
       "\n",
       "[57577 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_node_df = raw_sample_node_df.reset_index().rename(columns={'nodeId':'neo4jNodeId'}).rename(columns={'index':'nodeId'})\n",
    "sample_node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relationshipType</th>\n",
       "      <th>sourceNodeId</th>\n",
       "      <th>targetNodeId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CITES</td>\n",
       "      <td>0</td>\n",
       "      <td>48832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CITES</td>\n",
       "      <td>0</td>\n",
       "      <td>50197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CITES</td>\n",
       "      <td>0</td>\n",
       "      <td>50560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CITES</td>\n",
       "      <td>0</td>\n",
       "      <td>46074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CITES</td>\n",
       "      <td>1</td>\n",
       "      <td>30599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459923</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57575</td>\n",
       "      <td>13229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459924</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>32136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459925</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>36918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459926</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>36977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459927</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>26490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459928 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       relationshipType  sourceNodeId  targetNodeId\n",
       "0                 CITES             0         48832\n",
       "1                 CITES             0         50197\n",
       "2                 CITES             0         50560\n",
       "3                 CITES             0         46074\n",
       "4                 CITES             1         30599\n",
       "...                 ...           ...           ...\n",
       "459923            CITES         57575         13229\n",
       "459924            CITES         57576         32136\n",
       "459925            CITES         57576         36918\n",
       "459926            CITES         57576         36977\n",
       "459927            CITES         57576         26490\n",
       "\n",
       "[459928 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_topology_df = (raw_sample_topology_df\n",
    "    .merge(sample_node_df[['neo4jNodeId','nodeId']], how='left', \n",
    "           left_on='sourceNodeId', right_on='neo4jNodeId')\n",
    "    .drop(columns=['sourceNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'sourceNodeId'})\n",
    "    .merge(sample_node_df[['neo4jNodeId','nodeId']], how='left', \n",
    "           left_on='targetNodeId', right_on='neo4jNodeId')\n",
    "    .drop(columns=['targetNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'targetNodeId'})\n",
    ")\n",
    "sample_topology_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Inputs for Training\n",
    "Now that we re-assigned node ids, we can easily transform our `sample_topology_df` and `node_df` into the `edge_index`, features (`x`), and target (`y`) tensors for PyG. We will also use `node_df.year` for data splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using `by_rel_type` we get the topology in a format that can be used as input to several GNN frameworks:\n",
    "# {\"rel_type\": [[source_nodes], [target_nodes]]}\n",
    "sample_topology = sample_topology_df.by_rel_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 57576, 57576, 57576],\n",
       "        [48832, 50197, 50560,  ..., 36918, 36977, 26490]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(sample_topology['CITES'], dtype=torch.long)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node features\n",
    "x = torch.tensor(np.stack(sample_node_df['textEmbedding']), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target class\n",
    "y = torch.tensor(np.stack(sample_node_df['subjectId']), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[57577, 128], edge_index=[2, 459928], y=[57577], train_mask=[57577], val_mask=[57577], test_mask=[57577])\n"
     ]
    }
   ],
   "source": [
    "# data objects and masks for data splitting\n",
    "data = Data(x=x, y=y, edge_index=edge_index)\n",
    "data.train_mask = torch.tensor(np.stack(sample_node_df.year < VALID_YEAR))\n",
    "data.val_mask = torch.tensor(np.stack(sample_node_df.year == VALID_YEAR))\n",
    "data.test_mask = torch.tensor(np.stack(sample_node_df.year > VALID_YEAR))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 40 possible target classes\n"
     ]
    }
   ],
   "source": [
    "num_classes = y.unique().shape[0]\n",
    "print(f'there are {num_classes} possible target classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Convolutional Neural Network and Other Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GCN architecture\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 72)\n",
    "        self.conv2 = GCNConv(72, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # We use log_softmax and nll_loss instead of softmax output and cross entropy loss\n",
    "        # for reasons for performance and numerical stability.\n",
    "        # They are mathematically equivalent\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Prepare training by setting up for the chosen device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Let's see what device was chosen\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(128, 72)\n",
      "  (conv2): GCNConv(72, 40)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# In standard PyTorch fashion we instantiate our model, and transfer it to the memory of the chosen device\n",
    "model = GCN().to(device)\n",
    "\n",
    "# Let's inspect our model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass our input data to the chosen device too\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since hyperparameter tuning is out of scope for this small example, we initialize an\n",
    "# Adam optimizer with some fixed learning rate and weight decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train: 3.8124, Valid: 3.7650, Test: 3.7201\n",
      "Epoch: 001, Train: 3.3731, Valid: 3.2336, Test: 3.3666\n",
      "Epoch: 002, Train: 3.2592, Valid: 2.8746, Test: 3.0503\n",
      "Epoch: 003, Train: 3.3073, Valid: 2.7021, Test: 2.7979\n",
      "Epoch: 004, Train: 3.4405, Valid: 2.7065, Test: 2.6882\n",
      "Epoch: 005, Train: 3.3579, Valid: 2.6410, Test: 2.6505\n",
      "Epoch: 006, Train: 3.2403, Valid: 2.5980, Test: 2.6353\n",
      "Epoch: 007, Train: 3.1113, Valid: 2.5501, Test: 2.6210\n",
      "Epoch: 008, Train: 2.9964, Valid: 2.5046, Test: 2.6095\n",
      "Epoch: 009, Train: 2.9466, Valid: 2.4629, Test: 2.5795\n",
      "Epoch: 010, Train: 2.9036, Valid: 2.4082, Test: 2.5354\n",
      "Epoch: 011, Train: 2.8694, Valid: 2.3436, Test: 2.5014\n",
      "Epoch: 012, Train: 2.8564, Valid: 2.3194, Test: 2.4805\n",
      "Epoch: 013, Train: 2.8281, Valid: 2.2840, Test: 2.4312\n",
      "Epoch: 014, Train: 2.7816, Valid: 2.2448, Test: 2.4202\n",
      "Epoch: 015, Train: 2.7344, Valid: 2.2156, Test: 2.3927\n",
      "Epoch: 016, Train: 2.6814, Valid: 2.1843, Test: 2.3644\n",
      "Epoch: 017, Train: 2.6233, Valid: 2.1484, Test: 2.3403\n",
      "Epoch: 018, Train: 2.5788, Valid: 2.1209, Test: 2.3131\n",
      "Epoch: 019, Train: 2.5380, Valid: 2.0887, Test: 2.2892\n",
      "Epoch: 020, Train: 2.5052, Valid: 2.0615, Test: 2.2615\n",
      "Epoch: 021, Train: 2.4797, Valid: 2.0328, Test: 2.2173\n",
      "Epoch: 022, Train: 2.4561, Valid: 2.0083, Test: 2.2024\n",
      "Epoch: 023, Train: 2.4349, Valid: 1.9804, Test: 2.1753\n",
      "Epoch: 024, Train: 2.3983, Valid: 1.9549, Test: 2.1536\n",
      "Epoch: 025, Train: 2.3671, Valid: 1.9373, Test: 2.1480\n",
      "Epoch: 026, Train: 2.3225, Valid: 1.9084, Test: 2.1399\n",
      "Epoch: 027, Train: 2.2953, Valid: 1.8936, Test: 2.1253\n",
      "Epoch: 028, Train: 2.2717, Valid: 1.8685, Test: 2.0945\n",
      "Epoch: 029, Train: 2.2439, Valid: 1.8530, Test: 2.0793\n",
      "Epoch: 030, Train: 2.2159, Valid: 1.8304, Test: 2.0541\n",
      "Epoch: 031, Train: 2.1870, Valid: 1.8065, Test: 2.0378\n",
      "Epoch: 032, Train: 2.1577, Valid: 1.7899, Test: 2.0290\n",
      "Epoch: 033, Train: 2.1256, Valid: 1.7777, Test: 2.0174\n",
      "Epoch: 034, Train: 2.1022, Valid: 1.7541, Test: 2.0053\n",
      "Epoch: 035, Train: 2.0843, Valid: 1.7397, Test: 1.9889\n",
      "Epoch: 036, Train: 2.0659, Valid: 1.7279, Test: 1.9788\n",
      "Epoch: 037, Train: 2.0467, Valid: 1.7115, Test: 1.9643\n",
      "Epoch: 038, Train: 2.0241, Valid: 1.6970, Test: 1.9419\n",
      "Epoch: 039, Train: 2.0023, Valid: 1.6817, Test: 1.9352\n",
      "Epoch: 040, Train: 1.9870, Valid: 1.6677, Test: 1.9235\n",
      "Epoch: 041, Train: 1.9672, Valid: 1.6628, Test: 1.9261\n",
      "Epoch: 042, Train: 1.9533, Valid: 1.6483, Test: 1.9180\n",
      "Epoch: 043, Train: 1.9416, Valid: 1.6343, Test: 1.9052\n",
      "Epoch: 044, Train: 1.9185, Valid: 1.6269, Test: 1.8883\n",
      "Epoch: 045, Train: 1.8999, Valid: 1.6161, Test: 1.8859\n",
      "Epoch: 046, Train: 1.8918, Valid: 1.6079, Test: 1.8723\n",
      "Epoch: 047, Train: 1.8790, Valid: 1.5970, Test: 1.8642\n",
      "Epoch: 048, Train: 1.8737, Valid: 1.5897, Test: 1.8663\n",
      "Epoch: 049, Train: 1.8579, Valid: 1.5861, Test: 1.8550\n",
      "Epoch: 050, Train: 1.8456, Valid: 1.5640, Test: 1.8459\n",
      "Epoch: 051, Train: 1.8365, Valid: 1.5643, Test: 1.8608\n",
      "Epoch: 052, Train: 1.8236, Valid: 1.5491, Test: 1.8496\n",
      "Epoch: 053, Train: 1.8189, Valid: 1.5542, Test: 1.8392\n",
      "Epoch: 054, Train: 1.8089, Valid: 1.5501, Test: 1.8313\n",
      "Epoch: 055, Train: 1.8051, Valid: 1.5386, Test: 1.8113\n",
      "Epoch: 056, Train: 1.7989, Valid: 1.5300, Test: 1.8237\n",
      "Epoch: 057, Train: 1.7902, Valid: 1.5240, Test: 1.8250\n",
      "Epoch: 058, Train: 1.7836, Valid: 1.5173, Test: 1.8033\n",
      "Epoch: 059, Train: 1.7767, Valid: 1.5099, Test: 1.8002\n",
      "Epoch: 060, Train: 1.7739, Valid: 1.5104, Test: 1.8030\n",
      "Epoch: 061, Train: 1.7640, Valid: 1.5032, Test: 1.7918\n",
      "Epoch: 062, Train: 1.7490, Valid: 1.4884, Test: 1.7895\n",
      "Epoch: 063, Train: 1.7435, Valid: 1.4866, Test: 1.7906\n",
      "Epoch: 064, Train: 1.7415, Valid: 1.4856, Test: 1.7838\n",
      "Epoch: 065, Train: 1.7446, Valid: 1.4838, Test: 1.7804\n",
      "Epoch: 066, Train: 1.7315, Valid: 1.4711, Test: 1.7795\n",
      "Epoch: 067, Train: 1.7270, Valid: 1.4661, Test: 1.7669\n",
      "Epoch: 068, Train: 1.7238, Valid: 1.4699, Test: 1.7718\n",
      "Epoch: 069, Train: 1.7156, Valid: 1.4576, Test: 1.7667\n",
      "Epoch: 070, Train: 1.7038, Valid: 1.4610, Test: 1.7707\n",
      "Epoch: 071, Train: 1.7043, Valid: 1.4557, Test: 1.7681\n",
      "Epoch: 072, Train: 1.7025, Valid: 1.4505, Test: 1.7544\n",
      "Epoch: 073, Train: 1.7034, Valid: 1.4505, Test: 1.7529\n",
      "Epoch: 074, Train: 1.6974, Valid: 1.4433, Test: 1.7512\n",
      "Epoch: 075, Train: 1.6883, Valid: 1.4391, Test: 1.7533\n",
      "Epoch: 076, Train: 1.6891, Valid: 1.4386, Test: 1.7577\n",
      "Epoch: 077, Train: 1.6807, Valid: 1.4345, Test: 1.7370\n",
      "Epoch: 078, Train: 1.6774, Valid: 1.4277, Test: 1.7481\n",
      "Epoch: 079, Train: 1.6769, Valid: 1.4281, Test: 1.7471\n",
      "Epoch: 080, Train: 1.6689, Valid: 1.4190, Test: 1.7394\n",
      "Epoch: 081, Train: 1.6666, Valid: 1.4280, Test: 1.7465\n",
      "Epoch: 082, Train: 1.6555, Valid: 1.4136, Test: 1.7402\n",
      "Epoch: 083, Train: 1.6569, Valid: 1.4144, Test: 1.7345\n",
      "Epoch: 084, Train: 1.6668, Valid: 1.4046, Test: 1.7236\n",
      "Epoch: 085, Train: 1.6603, Valid: 1.4092, Test: 1.7401\n",
      "Epoch: 086, Train: 1.6517, Valid: 1.4037, Test: 1.7308\n",
      "Epoch: 087, Train: 1.6424, Valid: 1.3967, Test: 1.7468\n",
      "Epoch: 088, Train: 1.6483, Valid: 1.4024, Test: 1.7293\n",
      "Epoch: 089, Train: 1.6477, Valid: 1.3966, Test: 1.7269\n",
      "Epoch: 090, Train: 1.6502, Valid: 1.3914, Test: 1.7158\n",
      "Epoch: 091, Train: 1.6422, Valid: 1.3936, Test: 1.7245\n",
      "Epoch: 092, Train: 1.6348, Valid: 1.3897, Test: 1.7165\n",
      "Epoch: 093, Train: 1.6273, Valid: 1.3871, Test: 1.7208\n",
      "Epoch: 094, Train: 1.6334, Valid: 1.3863, Test: 1.7150\n",
      "Epoch: 095, Train: 1.6364, Valid: 1.3874, Test: 1.7109\n",
      "Epoch: 096, Train: 1.6379, Valid: 1.3776, Test: 1.7133\n",
      "Epoch: 097, Train: 1.6295, Valid: 1.3688, Test: 1.7094\n",
      "Epoch: 098, Train: 1.6271, Valid: 1.3777, Test: 1.7100\n",
      "Epoch: 099, Train: 1.6190, Valid: 1.3733, Test: 1.6941\n",
      "Epoch: 100, Train: 1.6293, Valid: 1.3804, Test: 1.7124\n",
      "Epoch: 101, Train: 1.6242, Valid: 1.3650, Test: 1.7008\n",
      "Epoch: 102, Train: 1.6279, Valid: 1.3640, Test: 1.7024\n",
      "Epoch: 103, Train: 1.6279, Valid: 1.3695, Test: 1.7112\n",
      "Epoch: 104, Train: 1.6187, Valid: 1.3678, Test: 1.7116\n",
      "Epoch: 105, Train: 1.6142, Valid: 1.3673, Test: 1.7134\n",
      "Epoch: 106, Train: 1.6148, Valid: 1.3719, Test: 1.7096\n",
      "Epoch: 107, Train: 1.6133, Valid: 1.3560, Test: 1.7023\n",
      "Epoch: 108, Train: 1.6175, Valid: 1.3629, Test: 1.6985\n",
      "Epoch: 109, Train: 1.6099, Valid: 1.3654, Test: 1.7083\n",
      "Epoch: 110, Train: 1.6027, Valid: 1.3600, Test: 1.7045\n",
      "Epoch: 111, Train: 1.6116, Valid: 1.3595, Test: 1.7086\n",
      "Epoch: 112, Train: 1.6158, Valid: 1.3511, Test: 1.7003\n",
      "Epoch: 113, Train: 1.6091, Valid: 1.3585, Test: 1.6863\n",
      "Epoch: 114, Train: 1.6025, Valid: 1.3478, Test: 1.7014\n",
      "Epoch: 115, Train: 1.6018, Valid: 1.3552, Test: 1.7039\n",
      "Epoch: 116, Train: 1.6126, Valid: 1.3498, Test: 1.6954\n",
      "Epoch: 117, Train: 1.6076, Valid: 1.3490, Test: 1.6920\n",
      "Epoch: 118, Train: 1.6080, Valid: 1.3509, Test: 1.6896\n",
      "Epoch: 119, Train: 1.5992, Valid: 1.3441, Test: 1.6896\n",
      "Epoch: 120, Train: 1.5967, Valid: 1.3433, Test: 1.6920\n",
      "Epoch: 121, Train: 1.5976, Valid: 1.3398, Test: 1.6978\n",
      "Epoch: 122, Train: 1.6032, Valid: 1.3462, Test: 1.6973\n",
      "Epoch: 123, Train: 1.6004, Valid: 1.3497, Test: 1.6823\n",
      "Epoch: 124, Train: 1.5925, Valid: 1.3466, Test: 1.6827\n",
      "Epoch: 125, Train: 1.5825, Valid: 1.3279, Test: 1.6826\n",
      "Epoch: 126, Train: 1.5992, Valid: 1.3422, Test: 1.6933\n",
      "Epoch: 127, Train: 1.5908, Valid: 1.3280, Test: 1.6837\n",
      "Epoch: 128, Train: 1.5964, Valid: 1.3406, Test: 1.6755\n",
      "Epoch: 129, Train: 1.5869, Valid: 1.3368, Test: 1.6822\n",
      "Epoch: 130, Train: 1.5871, Valid: 1.3266, Test: 1.6703\n",
      "Epoch: 131, Train: 1.5898, Valid: 1.3293, Test: 1.6736\n",
      "Epoch: 132, Train: 1.5946, Valid: 1.3302, Test: 1.6779\n",
      "Epoch: 133, Train: 1.5966, Valid: 1.3317, Test: 1.6811\n",
      "Epoch: 134, Train: 1.5831, Valid: 1.3179, Test: 1.6741\n",
      "Epoch: 135, Train: 1.5832, Valid: 1.3238, Test: 1.6818\n",
      "Epoch: 136, Train: 1.5883, Valid: 1.3235, Test: 1.6874\n",
      "Epoch: 137, Train: 1.5834, Valid: 1.3118, Test: 1.6758\n",
      "Epoch: 138, Train: 1.5800, Valid: 1.3179, Test: 1.6755\n",
      "Epoch: 139, Train: 1.5909, Valid: 1.3216, Test: 1.6777\n",
      "Epoch: 140, Train: 1.5816, Valid: 1.3260, Test: 1.6763\n",
      "Epoch: 141, Train: 1.5789, Valid: 1.3136, Test: 1.6721\n",
      "Epoch: 142, Train: 1.5793, Valid: 1.3136, Test: 1.6695\n",
      "Epoch: 143, Train: 1.5829, Valid: 1.3120, Test: 1.6684\n",
      "Epoch: 144, Train: 1.5787, Valid: 1.3111, Test: 1.6735\n",
      "Epoch: 145, Train: 1.5762, Valid: 1.3181, Test: 1.6723\n",
      "Epoch: 146, Train: 1.5795, Valid: 1.3068, Test: 1.6569\n",
      "Epoch: 147, Train: 1.5861, Valid: 1.3151, Test: 1.6754\n",
      "Epoch: 148, Train: 1.5741, Valid: 1.3118, Test: 1.6886\n",
      "Epoch: 149, Train: 1.5617, Valid: 1.3105, Test: 1.6756\n",
      "Epoch: 150, Train: 1.5658, Valid: 1.3082, Test: 1.6722\n",
      "Epoch: 151, Train: 1.5665, Valid: 1.3036, Test: 1.6658\n",
      "Epoch: 152, Train: 1.5680, Valid: 1.3179, Test: 1.6742\n",
      "Epoch: 153, Train: 1.5619, Valid: 1.2974, Test: 1.6610\n",
      "Epoch: 154, Train: 1.5718, Valid: 1.2932, Test: 1.6629\n",
      "Epoch: 155, Train: 1.5747, Valid: 1.3044, Test: 1.6628\n",
      "Epoch: 156, Train: 1.5612, Valid: 1.3074, Test: 1.6649\n",
      "Epoch: 157, Train: 1.5646, Valid: 1.3020, Test: 1.6698\n",
      "Epoch: 158, Train: 1.5619, Valid: 1.2982, Test: 1.6640\n",
      "Epoch: 159, Train: 1.5654, Valid: 1.2970, Test: 1.6659\n",
      "Epoch: 160, Train: 1.5712, Valid: 1.2984, Test: 1.6592\n",
      "Epoch: 161, Train: 1.5686, Valid: 1.2993, Test: 1.6613\n",
      "Epoch: 162, Train: 1.5638, Valid: 1.2938, Test: 1.6525\n",
      "Epoch: 163, Train: 1.5585, Valid: 1.2966, Test: 1.6659\n",
      "Epoch: 164, Train: 1.5535, Valid: 1.2913, Test: 1.6567\n",
      "Epoch: 165, Train: 1.5587, Valid: 1.3000, Test: 1.6605\n",
      "Epoch: 166, Train: 1.5662, Valid: 1.2937, Test: 1.6633\n",
      "Epoch: 167, Train: 1.5667, Valid: 1.2990, Test: 1.6644\n",
      "Epoch: 168, Train: 1.5598, Valid: 1.2892, Test: 1.6633\n",
      "Epoch: 169, Train: 1.5554, Valid: 1.2920, Test: 1.6598\n",
      "Epoch: 170, Train: 1.5592, Valid: 1.2908, Test: 1.6568\n",
      "Epoch: 171, Train: 1.5582, Valid: 1.2861, Test: 1.6458\n",
      "Epoch: 172, Train: 1.5525, Valid: 1.2866, Test: 1.6512\n",
      "Epoch: 173, Train: 1.5517, Valid: 1.2860, Test: 1.6590\n",
      "Epoch: 174, Train: 1.5614, Valid: 1.2919, Test: 1.6526\n",
      "Epoch: 175, Train: 1.5555, Valid: 1.2827, Test: 1.6478\n",
      "Epoch: 176, Train: 1.5528, Valid: 1.2729, Test: 1.6662\n",
      "Epoch: 177, Train: 1.5468, Valid: 1.2757, Test: 1.6507\n",
      "Epoch: 178, Train: 1.5549, Valid: 1.2879, Test: 1.6489\n",
      "Epoch: 179, Train: 1.5590, Valid: 1.2788, Test: 1.6416\n",
      "Epoch: 180, Train: 1.5537, Valid: 1.2915, Test: 1.6559\n",
      "Epoch: 181, Train: 1.5532, Valid: 1.2947, Test: 1.6562\n",
      "Epoch: 182, Train: 1.5524, Valid: 1.2863, Test: 1.6533\n",
      "Epoch: 183, Train: 1.5457, Valid: 1.2860, Test: 1.6575\n",
      "Epoch: 184, Train: 1.5448, Valid: 1.2777, Test: 1.6527\n",
      "Epoch: 185, Train: 1.5414, Valid: 1.2771, Test: 1.6572\n",
      "Epoch: 186, Train: 1.5436, Valid: 1.2750, Test: 1.6493\n",
      "Epoch: 187, Train: 1.5451, Valid: 1.2799, Test: 1.6609\n",
      "Epoch: 188, Train: 1.5392, Valid: 1.2741, Test: 1.6624\n",
      "Epoch: 189, Train: 1.5502, Valid: 1.2707, Test: 1.6573\n",
      "Epoch: 190, Train: 1.5607, Valid: 1.2769, Test: 1.6490\n",
      "Epoch: 191, Train: 1.5544, Valid: 1.2683, Test: 1.6425\n",
      "Epoch: 192, Train: 1.5374, Valid: 1.2660, Test: 1.6524\n",
      "Epoch: 193, Train: 1.5368, Valid: 1.2707, Test: 1.6530\n",
      "Epoch: 194, Train: 1.5493, Valid: 1.2719, Test: 1.6437\n",
      "Epoch: 195, Train: 1.5520, Valid: 1.2676, Test: 1.6480\n",
      "Epoch: 196, Train: 1.5394, Valid: 1.2727, Test: 1.6520\n",
      "Epoch: 197, Train: 1.5432, Valid: 1.2716, Test: 1.6426\n",
      "Epoch: 198, Train: 1.5435, Valid: 1.2693, Test: 1.6525\n",
      "Epoch: 199, Train: 1.5381, Valid: 1.2701, Test: 1.6495\n"
     ]
    }
   ],
   "source": [
    "# Train the GCN using the CORA sample represented by `data` using the standard PyTorch training loop\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    train_loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    valid_loss = F.nll_loss(out[data.val_mask], data.y[data.val_mask])\n",
    "    test_loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask])\n",
    "    print(f'Epoch: {epoch:03d}, '\n",
    "      f'Train: {train_loss:.4f}, '\n",
    "      f'Valid: {valid_loss:.4f}, '\n",
    "      f'Test: {test_loss:.4f}')\n",
    "    valid_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.5820\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained GCN model on our test set\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f\"Test Set Accuracy: {acc:.4f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt with Full Graph\n",
    "Let's try again with the full graph as a quick sanity check.  The final accuracy should be close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[169343, 128], edge_index=[2, 1166243], y=[169343], train_mask=[169343], val_mask=[169343], test_mask=[169343])\n",
      "there are 40 possible target classes\n",
      "GCN(\n",
      "  (conv1): GCNConv(128, 72)\n",
      "  (conv2): GCNConv(72, 40)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "raw_topology_df = gds.beta.graph.relationships.stream(g)\n",
    "\n",
    "raw_node_df = gds.graph.nodeProperties.stream(\n",
    "    g,\n",
    "    ['subjectId', 'year', 'textEmbedding'],\n",
    "    separate_property_columns=True,\n",
    ")\n",
    "\n",
    "node_df = raw_node_df.reset_index().rename(columns={'nodeId':'neo4jNodeId'}).rename(columns={'index':'nodeId'})\n",
    "\n",
    "topology_df = (raw_topology_df\n",
    "    .merge(node_df[['neo4jNodeId','nodeId']], how='left', left_on='sourceNodeId', \n",
    "           right_on='neo4jNodeId')\n",
    "    .drop(columns=['sourceNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'sourceNodeId'})\n",
    "    .merge(node_df[['neo4jNodeId','nodeId']], how='left', left_on='targetNodeId', \n",
    "           right_on='neo4jNodeId')\n",
    "    .drop(columns=['targetNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'targetNodeId'})\n",
    ")\n",
    "\n",
    "topology = topology_df.by_rel_type()\n",
    "\n",
    "edge_index = torch.tensor(topology['CITES'], dtype=torch.long)\n",
    "\n",
    "x = torch.tensor(np.stack(node_df['textEmbedding']), dtype=torch.float)\n",
    "y = torch.tensor(np.stack(node_df['subjectId']), dtype=torch.long)\n",
    "\n",
    "full_data = Data(x=x, y=y, edge_index=edge_index)\n",
    "full_data.train_mask = torch.tensor(np.stack(node_df.year < VALID_YEAR))\n",
    "full_data.val_mask = torch.tensor(np.stack(node_df.year == VALID_YEAR))\n",
    "full_data.test_mask = torch.tensor(np.stack(node_df.year > VALID_YEAR))\n",
    "print(full_data)\n",
    "\n",
    "num_classes = y.unique().shape[0]\n",
    "print(f'there are {num_classes} possible target classes')\n",
    "\n",
    "full_model = GCN().to(device)\n",
    "print(full_model)\n",
    "\n",
    "full_data = full_data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(full_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "full_model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = full_model(full_data)\n",
    "    train_loss = F.nll_loss(out[full_data.train_mask], full_data.y[full_data.train_mask])\n",
    "    valid_loss = F.nll_loss(out[full_data.val_mask], full_data.y[full_data.val_mask])\n",
    "    test_loss = F.nll_loss(out[full_data.test_mask], full_data.y[full_data.test_mask])\n",
    "    valid_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for full dataset: 0.5583\n",
      "This is a difference of -2.37 percentage points from the sampled dataset\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the full data trained GCN model on our test set\n",
    "full_model.eval()\n",
    "full_pred = full_model(full_data).argmax(dim=1)\n",
    "full_correct = (full_pred[full_data.test_mask] == full_data.y[full_data.test_mask]).sum()\n",
    "full_acc = int(full_correct) / int(full_data.test_mask.sum())\n",
    "\n",
    "print(f'Test set accuracy for full dataset: {full_acc:.4f}')\n",
    "print(f'This is a difference of {100*(full_acc-acc):.2f} percentage points from the sampled dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Remove Neo4j graph projections to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graphName                                                             proj\n",
       "database                                                             neo4j\n",
       "memoryUsage                                                               \n",
       "sizeInBytes                                                             -1\n",
       "nodeCount                                                           169343\n",
       "relationshipCount                                                  1166243\n",
       "configuration                                                           {}\n",
       "density                                                           0.000041\n",
       "creationTime                           2023-03-16T00:15:45.934077784+00:00\n",
       "modificationTime                       2023-03-16T00:15:47.662464173+00:00\n",
       "schema                   {'graphProperties': {}, 'relationships': {'CIT...\n",
       "schemaWithOrientation    {'graphProperties': {}, 'relationships': {'CIT...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_sample.drop()\n",
    "g.drop()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
