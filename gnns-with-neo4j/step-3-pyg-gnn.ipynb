{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Graph Sampling for PyG GNN \n",
    "__An example using the [`ogbn-arxiv`](https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv) dataset__\n",
    "\n",
    "![Neo4j version](https://img.shields.io/badge/Neo4j-5-brightgreen)\n",
    "![GDS version](https://img.shields.io/badge/GDS-2.3-brightgreen)\n",
    "![GDS Python Client version](https://img.shields.io/badge/GDS_Python_Client-1.6-brightgreen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphdatascience in /opt/conda/lib/python3.7/site-packages (1.6)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.7/site-packages (0.21.1)\n",
      "Requirement already satisfied: pyarrow<11.0,>=4.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (7.0.0)\n",
      "Requirement already satisfied: multimethod<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (1.9.1)\n",
      "Requirement already satisfied: neo4j<6.0,>=4.4.2 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (5.6.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (4.64.1)\n",
      "Requirement already satisfied: pandas<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from graphdatascience) (1.3.5)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from neo4j<6.0,>=4.4.2->graphdatascience) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0->graphdatascience) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0->graphdatascience) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas<2.0,>=1.0->graphdatascience) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install graphdatascience python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphdatascience import GraphDataScience\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from numpy.typing import ArrayLike\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv('db-credentials.env', override=True)\n",
    "\n",
    "# Use Neo4j URI and credentials according to our setup\n",
    "gds = GraphDataScience(\n",
    "    os.getenv('NEO4J_URI'),\n",
    "    auth=(os.getenv('NEO4J_USERNAME'),\n",
    "          os.getenv('NEO4J_PASSWORD')),\n",
    "    aura_ds=eval(os.getenv('AURA_DS').title()))\n",
    "\n",
    "# Necessary if you enabled Arrow on the db - this is true for AuraDS\n",
    "gds.set_database(\"neo4j\")\n",
    "PROJ_NAME = 'proj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 7474\n",
    "VALID_YEAR = 2018\n",
    "SAMPLE_RATIO = 0.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampl Neo4j Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gds.graph.exists(PROJ_NAME)['exists']:\n",
    "    gds.graph.get(PROJ_NAME).drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bf4bd0b52745e79c901b16c694266a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:   0%|          | 0/100 [00:00<?, ?%/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 ms, sys: 326 Âµs, total: 30.7 ms\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g, _ = gds.graph.project(PROJ_NAME, ['Train', 'Valid', 'Test'], ['CITES'], nodeProperties =['textEmbedding', 'subjectId', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in our graph: 169,343\n",
      "Number of relationships in our graph: 1,166,243\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nodes in our graph: {g.node_count():,}\")\n",
    "print(f\"Number of relationships in our graph: {g.relationship_count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PROJ_NAME = PROJ_NAME + '_sample'\n",
    "if gds.graph.exists(SAMPLE_PROJ_NAME)['exists']:\n",
    "    gds.graph.get(SAMPLE_PROJ_NAME).drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09c19c083864eb4b9a6fb93a1071125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Random walk with restarts sampling:   0%|          | 0/100 [00:00<?, ?%/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 406 ms, sys: 61.7 ms, total: 468 ms\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g_sample, _ = gds.alpha.graph.sample.rwr(SAMPLE_PROJ_NAME, g, samplingRatio=SAMPLE_RATIO,\n",
    "                                         restartProbability=0.05, nodeLabelStratification=True, concurrency=1, randomSeed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in our sample: 57,577\n",
      "Number of relationships in our sample: 459,928\n"
     ]
    }
   ],
   "source": [
    "# If our SAMPLE_RATIO is 0.34 we should have somewhere around 0.34 * 269,343 ~ 55,883 nodes in our sample\n",
    "print(f\"Number of nodes in our sample: {g_sample.node_count():,}\")\n",
    "\n",
    "# And let's see how many relationships we have\n",
    "print(f\"Number of relationships in our sample: {g_sample.relationship_count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree distribution in our full graph:\n",
      "p99      37.000000\n",
      "min       0.000000\n",
      "max     436.000000\n",
      "mean      6.886869\n",
      "p90      18.000000\n",
      "p50       4.000000\n",
      "p999     71.000000\n",
      "p95      24.000000\n",
      "p75       9.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Degree distribution in our sample:\n",
      "p99      40.000000\n",
      "min       0.000000\n",
      "max     403.000000\n",
      "mean      7.988051\n",
      "p90      20.000000\n",
      "p50       5.000000\n",
      "p999     82.000000\n",
      "p95      26.000000\n",
      "p75      11.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We should also see similar degree distributions\n",
    "print(f\"Degree distribution in our full graph:\")\n",
    "print(g.degree_distribution())\n",
    "\n",
    "# And let's see how many relationships we got\n",
    "print(f\"\\n\\nDegree distribution in our sample:\")\n",
    "print(g_sample.degree_distribution())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Sampled Graph to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_topology_df = gds.beta.graph.relationships.stream(g_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_node_df = gds.graph.nodeProperties.stream(\n",
    "    g_sample,\n",
    "    ['subjectId', 'year', 'textEmbedding'],\n",
    "    separate_property_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Index Graph Data for PyG\n",
    "PyG needs an ordered index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeId</th>\n",
       "      <th>neo4jNodeId</th>\n",
       "      <th>subjectId</th>\n",
       "      <th>year</th>\n",
       "      <th>textEmbedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>112370</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>[-0.03758800029754639, -0.019776999950408936, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112371</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>[-0.09249299764633179, 0.06776200234889984, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>112375</td>\n",
       "      <td>10</td>\n",
       "      <td>2011</td>\n",
       "      <td>[-0.05762699991464615, -0.02996399998664856, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>112376</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>[-0.010092999786138535, -0.06655500084161758, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>112380</td>\n",
       "      <td>10</td>\n",
       "      <td>2000</td>\n",
       "      <td>[-0.0767190009355545, -0.13565599918365479, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57572</th>\n",
       "      <td>57572</td>\n",
       "      <td>52393</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.04432599991559982, -0.05412999913096428, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57573</th>\n",
       "      <td>57573</td>\n",
       "      <td>52398</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.17306800186634064, 0.027883000671863556, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57574</th>\n",
       "      <td>57574</td>\n",
       "      <td>52404</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.13642600178718567, -0.03896800056099892, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57575</th>\n",
       "      <td>57575</td>\n",
       "      <td>52405</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[-0.33581000566482544, 0.2053699940443039, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57576</th>\n",
       "      <td>57576</td>\n",
       "      <td>52408</td>\n",
       "      <td>24</td>\n",
       "      <td>2019</td>\n",
       "      <td>[0.04785099998116493, 0.07365299761295319, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57577 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nodeId  neo4jNodeId  subjectId  year  \\\n",
       "0           0       112370         10  2012   \n",
       "1           1       112371         10  2013   \n",
       "2           2       112375         10  2011   \n",
       "3           3       112376         10  2013   \n",
       "4           4       112380         10  2000   \n",
       "...       ...          ...        ...   ...   \n",
       "57572   57572        52393         24  2019   \n",
       "57573   57573        52398         24  2019   \n",
       "57574   57574        52404         24  2019   \n",
       "57575   57575        52405         24  2019   \n",
       "57576   57576        52408         24  2019   \n",
       "\n",
       "                                           textEmbedding  \n",
       "0      [-0.03758800029754639, -0.019776999950408936, ...  \n",
       "1      [-0.09249299764633179, 0.06776200234889984, -0...  \n",
       "2      [-0.05762699991464615, -0.02996399998664856, -...  \n",
       "3      [-0.010092999786138535, -0.06655500084161758, ...  \n",
       "4      [-0.0767190009355545, -0.13565599918365479, -0...  \n",
       "...                                                  ...  \n",
       "57572  [-0.04432599991559982, -0.05412999913096428, -...  \n",
       "57573  [-0.17306800186634064, 0.027883000671863556, -...  \n",
       "57574  [-0.13642600178718567, -0.03896800056099892, -...  \n",
       "57575  [-0.33581000566482544, 0.2053699940443039, -0....  \n",
       "57576  [0.04785099998116493, 0.07365299761295319, -0....  \n",
       "\n",
       "[57577 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_node_df = raw_sample_node_df.reset_index().rename(columns={'nodeId':'neo4jNodeId'}).rename(columns={'index':'nodeId'})\n",
    "sample_node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relationshipType</th>\n",
       "      <th>sourceNodeId</th>\n",
       "      <th>targetNodeId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CITES</td>\n",
       "      <td>20000</td>\n",
       "      <td>38218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CITES</td>\n",
       "      <td>20002</td>\n",
       "      <td>39028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CITES</td>\n",
       "      <td>20002</td>\n",
       "      <td>39224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CITES</td>\n",
       "      <td>20002</td>\n",
       "      <td>47274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CITES</td>\n",
       "      <td>20005</td>\n",
       "      <td>20030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459923</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57575</td>\n",
       "      <td>40806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459924</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>22136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459925</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>26918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459926</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>26977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459927</th>\n",
       "      <td>CITES</td>\n",
       "      <td>57576</td>\n",
       "      <td>6490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459928 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       relationshipType  sourceNodeId  targetNodeId\n",
       "0                 CITES         20000         38218\n",
       "1                 CITES         20002         39028\n",
       "2                 CITES         20002         39224\n",
       "3                 CITES         20002         47274\n",
       "4                 CITES         20005         20030\n",
       "...                 ...           ...           ...\n",
       "459923            CITES         57575         40806\n",
       "459924            CITES         57576         22136\n",
       "459925            CITES         57576         26918\n",
       "459926            CITES         57576         26977\n",
       "459927            CITES         57576          6490\n",
       "\n",
       "[459928 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_topology_df = (raw_sample_topology_df\n",
    "    .merge(sample_node_df[['neo4jNodeId','nodeId']], how='left', left_on='sourceNodeId', right_on='neo4jNodeId')\n",
    "    .drop(columns=['sourceNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'sourceNodeId'})\n",
    "    .merge(sample_node_df[['neo4jNodeId','nodeId']], how='left', left_on='targetNodeId', right_on='neo4jNodeId')\n",
    "    .drop(columns=['targetNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'targetNodeId'})\n",
    ")\n",
    "sample_topology_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Inputs for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using `by_rel_type` we get the topology in a format that can be used as input to several GNN frameworks:\n",
    "# {\"rel_type\": [[source_nodes], [target_nodes]]}\n",
    "sample_topology = sample_topology_df.by_rel_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20000, 20002, 20002,  ..., 57576, 57576, 57576],\n",
       "        [38218, 39028, 39224,  ..., 26918, 26977,  6490]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(sample_topology['CITES'], dtype=torch.long)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.stack(sample_node_df['textEmbedding']), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(np.stack(sample_node_df['subjectId']), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[57577, 128], edge_index=[2, 459928], y=[57577], train_mask=[57577], val_mask=[57577], test_mask=[57577])\n"
     ]
    }
   ],
   "source": [
    "data = Data(x=x, y=y, edge_index=edge_index)\n",
    "data.train_mask = torch.tensor(np.stack(sample_node_df.year < VALID_YEAR))\n",
    "data.val_mask = torch.tensor(np.stack(sample_node_df.year == VALID_YEAR))\n",
    "data.test_mask = torch.tensor(np.stack(sample_node_df.year > VALID_YEAR))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 40 possible target classes\n"
     ]
    }
   ],
   "source": [
    "num_classes = y.unique().shape[0]\n",
    "print(f'there are {num_classes} possible target classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Convolutional Nueral Network and Other Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GCN architecture\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 72)\n",
    "        self.conv2 = GCNConv(72, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # We use log_softmax and nll_loss instead of softmax output and cross entropy loss\n",
    "        # for reasons for performance and numerical stability.\n",
    "        # They are mathematically equivalent\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Prepare training by setting up for the chosen device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Let's see what device was chosen\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(128, 72)\n",
      "  (conv2): GCNConv(72, 40)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# In standard PyTorch fashion we instantiate our model, and transfer it to the memory of the chosen device\n",
    "model = GCN().to(device)\n",
    "\n",
    "# Let's inspect our model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass our input data to the chosen device too\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since hyperparameter tuning is out of scope for this small example, we initialize an\n",
    "# Adam optimizer with some fixed learning rate and weight decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train: 3.6372, Valid: 3.6192, Test: 3.6436\n",
      "Epoch: 001, Train: 3.3100, Valid: 3.0667, Test: 3.1962\n",
      "Epoch: 002, Train: 3.3278, Valid: 2.8460, Test: 2.9109\n",
      "Epoch: 003, Train: 3.3234, Valid: 2.7527, Test: 2.7664\n",
      "Epoch: 004, Train: 3.1973, Valid: 2.6637, Test: 2.7154\n",
      "Epoch: 005, Train: 3.1076, Valid: 2.6448, Test: 2.7097\n",
      "Epoch: 006, Train: 3.0156, Valid: 2.5776, Test: 2.6657\n",
      "Epoch: 007, Train: 2.9657, Valid: 2.5028, Test: 2.6078\n",
      "Epoch: 008, Train: 2.9486, Valid: 2.4663, Test: 2.5776\n",
      "Epoch: 009, Train: 2.9336, Valid: 2.4291, Test: 2.5490\n",
      "Epoch: 010, Train: 2.8895, Valid: 2.3839, Test: 2.5330\n",
      "Epoch: 011, Train: 2.8353, Valid: 2.3449, Test: 2.4954\n",
      "Epoch: 012, Train: 2.7676, Valid: 2.2982, Test: 2.4792\n",
      "Epoch: 013, Train: 2.7135, Valid: 2.2692, Test: 2.4552\n",
      "Epoch: 014, Train: 2.6766, Valid: 2.2263, Test: 2.4250\n",
      "Epoch: 015, Train: 2.6482, Valid: 2.2006, Test: 2.3736\n",
      "Epoch: 016, Train: 2.6276, Valid: 2.1663, Test: 2.3400\n",
      "Epoch: 017, Train: 2.5844, Valid: 2.1317, Test: 2.3052\n",
      "Epoch: 018, Train: 2.5456, Valid: 2.1058, Test: 2.2868\n",
      "Epoch: 019, Train: 2.4906, Valid: 2.0697, Test: 2.2630\n",
      "Epoch: 020, Train: 2.4399, Valid: 2.0428, Test: 2.2517\n",
      "Epoch: 021, Train: 2.3996, Valid: 2.0139, Test: 2.2307\n",
      "Epoch: 022, Train: 2.3591, Valid: 1.9862, Test: 2.2075\n",
      "Epoch: 023, Train: 2.3363, Valid: 1.9556, Test: 2.1814\n",
      "Epoch: 024, Train: 2.3135, Valid: 1.9457, Test: 2.1585\n",
      "Epoch: 025, Train: 2.2972, Valid: 1.9192, Test: 2.1330\n",
      "Epoch: 026, Train: 2.2642, Valid: 1.8893, Test: 2.1175\n",
      "Epoch: 027, Train: 2.2298, Valid: 1.8776, Test: 2.1025\n",
      "Epoch: 028, Train: 2.1959, Valid: 1.8529, Test: 2.0982\n",
      "Epoch: 029, Train: 2.1730, Valid: 1.8341, Test: 2.0875\n",
      "Epoch: 030, Train: 2.1477, Valid: 1.8154, Test: 2.0639\n",
      "Epoch: 031, Train: 2.1292, Valid: 1.8009, Test: 2.0420\n",
      "Epoch: 032, Train: 2.1139, Valid: 1.7878, Test: 2.0285\n",
      "Epoch: 033, Train: 2.0975, Valid: 1.7711, Test: 2.0217\n",
      "Epoch: 034, Train: 2.0778, Valid: 1.7549, Test: 2.0014\n",
      "Epoch: 035, Train: 2.0617, Valid: 1.7421, Test: 1.9959\n",
      "Epoch: 036, Train: 2.0359, Valid: 1.7259, Test: 1.9882\n",
      "Epoch: 037, Train: 2.0186, Valid: 1.7158, Test: 1.9766\n",
      "Epoch: 038, Train: 2.0038, Valid: 1.6961, Test: 1.9632\n",
      "Epoch: 039, Train: 1.9913, Valid: 1.6853, Test: 1.9544\n",
      "Epoch: 040, Train: 1.9762, Valid: 1.6692, Test: 1.9458\n",
      "Epoch: 041, Train: 1.9670, Valid: 1.6607, Test: 1.9289\n",
      "Epoch: 042, Train: 1.9523, Valid: 1.6457, Test: 1.9110\n",
      "Epoch: 043, Train: 1.9435, Valid: 1.6327, Test: 1.9122\n",
      "Epoch: 044, Train: 1.9254, Valid: 1.6208, Test: 1.8998\n",
      "Epoch: 045, Train: 1.9123, Valid: 1.6122, Test: 1.8942\n",
      "Epoch: 046, Train: 1.9002, Valid: 1.6087, Test: 1.8869\n",
      "Epoch: 047, Train: 1.8936, Valid: 1.5989, Test: 1.8814\n",
      "Epoch: 048, Train: 1.8834, Valid: 1.6002, Test: 1.8734\n",
      "Epoch: 049, Train: 1.8722, Valid: 1.5798, Test: 1.8695\n",
      "Epoch: 050, Train: 1.8684, Valid: 1.5843, Test: 1.8672\n",
      "Epoch: 051, Train: 1.8558, Valid: 1.5637, Test: 1.8593\n",
      "Epoch: 052, Train: 1.8446, Valid: 1.5632, Test: 1.8564\n",
      "Epoch: 053, Train: 1.8248, Valid: 1.5562, Test: 1.8444\n",
      "Epoch: 054, Train: 1.8203, Valid: 1.5458, Test: 1.8351\n",
      "Epoch: 055, Train: 1.8112, Valid: 1.5410, Test: 1.8259\n",
      "Epoch: 056, Train: 1.8125, Valid: 1.5359, Test: 1.8291\n",
      "Epoch: 057, Train: 1.8042, Valid: 1.5174, Test: 1.8121\n",
      "Epoch: 058, Train: 1.7912, Valid: 1.5177, Test: 1.8125\n",
      "Epoch: 059, Train: 1.7841, Valid: 1.5169, Test: 1.8210\n",
      "Epoch: 060, Train: 1.7781, Valid: 1.5074, Test: 1.8159\n",
      "Epoch: 061, Train: 1.7698, Valid: 1.5087, Test: 1.8064\n",
      "Epoch: 062, Train: 1.7671, Valid: 1.4995, Test: 1.7993\n",
      "Epoch: 063, Train: 1.7611, Valid: 1.4889, Test: 1.7935\n",
      "Epoch: 064, Train: 1.7480, Valid: 1.4880, Test: 1.7940\n",
      "Epoch: 065, Train: 1.7476, Valid: 1.4845, Test: 1.7963\n",
      "Epoch: 066, Train: 1.7380, Valid: 1.4712, Test: 1.7803\n",
      "Epoch: 067, Train: 1.7235, Valid: 1.4781, Test: 1.7867\n",
      "Epoch: 068, Train: 1.7312, Valid: 1.4806, Test: 1.7928\n",
      "Epoch: 069, Train: 1.7233, Valid: 1.4720, Test: 1.7790\n",
      "Epoch: 070, Train: 1.7204, Valid: 1.4636, Test: 1.7785\n",
      "Epoch: 071, Train: 1.7161, Valid: 1.4557, Test: 1.7674\n",
      "Epoch: 072, Train: 1.7117, Valid: 1.4492, Test: 1.7639\n",
      "Epoch: 073, Train: 1.7098, Valid: 1.4512, Test: 1.7666\n",
      "Epoch: 074, Train: 1.6970, Valid: 1.4439, Test: 1.7578\n",
      "Epoch: 075, Train: 1.7023, Valid: 1.4451, Test: 1.7555\n",
      "Epoch: 076, Train: 1.7020, Valid: 1.4404, Test: 1.7484\n",
      "Epoch: 077, Train: 1.6939, Valid: 1.4385, Test: 1.7566\n",
      "Epoch: 078, Train: 1.6902, Valid: 1.4342, Test: 1.7553\n",
      "Epoch: 079, Train: 1.6908, Valid: 1.4325, Test: 1.7534\n",
      "Epoch: 080, Train: 1.6879, Valid: 1.4176, Test: 1.7473\n",
      "Epoch: 081, Train: 1.6750, Valid: 1.4124, Test: 1.7544\n",
      "Epoch: 082, Train: 1.6734, Valid: 1.4172, Test: 1.7452\n",
      "Epoch: 083, Train: 1.6814, Valid: 1.4159, Test: 1.7362\n",
      "Epoch: 084, Train: 1.6692, Valid: 1.4127, Test: 1.7499\n",
      "Epoch: 085, Train: 1.6644, Valid: 1.4181, Test: 1.7428\n",
      "Epoch: 086, Train: 1.6607, Valid: 1.4093, Test: 1.7496\n",
      "Epoch: 087, Train: 1.6655, Valid: 1.4073, Test: 1.7367\n",
      "Epoch: 088, Train: 1.6544, Valid: 1.4018, Test: 1.7226\n",
      "Epoch: 089, Train: 1.6577, Valid: 1.4043, Test: 1.7366\n",
      "Epoch: 090, Train: 1.6590, Valid: 1.4014, Test: 1.7248\n",
      "Epoch: 091, Train: 1.6497, Valid: 1.4008, Test: 1.7330\n",
      "Epoch: 092, Train: 1.6461, Valid: 1.4004, Test: 1.7304\n",
      "Epoch: 093, Train: 1.6564, Valid: 1.3982, Test: 1.7240\n",
      "Epoch: 094, Train: 1.6452, Valid: 1.3890, Test: 1.7294\n",
      "Epoch: 095, Train: 1.6456, Valid: 1.3867, Test: 1.7311\n",
      "Epoch: 096, Train: 1.6484, Valid: 1.3848, Test: 1.7279\n",
      "Epoch: 097, Train: 1.6412, Valid: 1.3902, Test: 1.7292\n",
      "Epoch: 098, Train: 1.6441, Valid: 1.3717, Test: 1.7125\n",
      "Epoch: 099, Train: 1.6429, Valid: 1.3788, Test: 1.7179\n",
      "Epoch: 100, Train: 1.6350, Valid: 1.3713, Test: 1.7166\n",
      "Epoch: 101, Train: 1.6380, Valid: 1.3746, Test: 1.7235\n",
      "Epoch: 102, Train: 1.6363, Valid: 1.3706, Test: 1.7109\n",
      "Epoch: 103, Train: 1.6345, Valid: 1.3703, Test: 1.7148\n",
      "Epoch: 104, Train: 1.6327, Valid: 1.3704, Test: 1.7062\n",
      "Epoch: 105, Train: 1.6302, Valid: 1.3744, Test: 1.7151\n",
      "Epoch: 106, Train: 1.6272, Valid: 1.3661, Test: 1.7194\n",
      "Epoch: 107, Train: 1.6261, Valid: 1.3582, Test: 1.7059\n",
      "Epoch: 108, Train: 1.6246, Valid: 1.3641, Test: 1.7072\n",
      "Epoch: 109, Train: 1.6311, Valid: 1.3511, Test: 1.7052\n",
      "Epoch: 110, Train: 1.6308, Valid: 1.3613, Test: 1.7080\n",
      "Epoch: 111, Train: 1.6265, Valid: 1.3583, Test: 1.7067\n",
      "Epoch: 112, Train: 1.6220, Valid: 1.3581, Test: 1.7020\n",
      "Epoch: 113, Train: 1.6146, Valid: 1.3582, Test: 1.7131\n",
      "Epoch: 114, Train: 1.6145, Valid: 1.3562, Test: 1.7060\n",
      "Epoch: 115, Train: 1.6145, Valid: 1.3459, Test: 1.7041\n",
      "Epoch: 116, Train: 1.6140, Valid: 1.3516, Test: 1.7044\n",
      "Epoch: 117, Train: 1.6201, Valid: 1.3372, Test: 1.6920\n",
      "Epoch: 118, Train: 1.6166, Valid: 1.3509, Test: 1.6900\n",
      "Epoch: 119, Train: 1.6173, Valid: 1.3428, Test: 1.7034\n",
      "Epoch: 120, Train: 1.6109, Valid: 1.3370, Test: 1.6958\n",
      "Epoch: 121, Train: 1.6049, Valid: 1.3468, Test: 1.6928\n",
      "Epoch: 122, Train: 1.6086, Valid: 1.3440, Test: 1.6866\n",
      "Epoch: 123, Train: 1.6100, Valid: 1.3431, Test: 1.6994\n",
      "Epoch: 124, Train: 1.5999, Valid: 1.3372, Test: 1.7016\n",
      "Epoch: 125, Train: 1.6064, Valid: 1.3401, Test: 1.6866\n",
      "Epoch: 126, Train: 1.6064, Valid: 1.3273, Test: 1.6862\n",
      "Epoch: 127, Train: 1.6059, Valid: 1.3312, Test: 1.6944\n",
      "Epoch: 128, Train: 1.6122, Valid: 1.3345, Test: 1.6950\n",
      "Epoch: 129, Train: 1.6049, Valid: 1.3383, Test: 1.6808\n",
      "Epoch: 130, Train: 1.6069, Valid: 1.3343, Test: 1.6929\n",
      "Epoch: 131, Train: 1.6041, Valid: 1.3291, Test: 1.6946\n",
      "Epoch: 132, Train: 1.5948, Valid: 1.3209, Test: 1.6877\n",
      "Epoch: 133, Train: 1.5998, Valid: 1.3229, Test: 1.6835\n",
      "Epoch: 134, Train: 1.5915, Valid: 1.3283, Test: 1.6771\n",
      "Epoch: 135, Train: 1.5978, Valid: 1.3291, Test: 1.6842\n",
      "Epoch: 136, Train: 1.5948, Valid: 1.3363, Test: 1.6936\n",
      "Epoch: 137, Train: 1.5901, Valid: 1.3322, Test: 1.6944\n",
      "Epoch: 138, Train: 1.5929, Valid: 1.3210, Test: 1.6962\n",
      "Epoch: 139, Train: 1.5956, Valid: 1.3260, Test: 1.6844\n",
      "Epoch: 140, Train: 1.5920, Valid: 1.3202, Test: 1.6787\n",
      "Epoch: 141, Train: 1.5887, Valid: 1.3151, Test: 1.6909\n",
      "Epoch: 142, Train: 1.5904, Valid: 1.3137, Test: 1.6788\n",
      "Epoch: 143, Train: 1.5894, Valid: 1.3184, Test: 1.6807\n",
      "Epoch: 144, Train: 1.5911, Valid: 1.3164, Test: 1.6882\n",
      "Epoch: 145, Train: 1.5828, Valid: 1.3211, Test: 1.6808\n",
      "Epoch: 146, Train: 1.5808, Valid: 1.3125, Test: 1.6878\n",
      "Epoch: 147, Train: 1.5891, Valid: 1.3129, Test: 1.6654\n",
      "Epoch: 148, Train: 1.5882, Valid: 1.3096, Test: 1.6790\n",
      "Epoch: 149, Train: 1.5899, Valid: 1.3191, Test: 1.6821\n",
      "Epoch: 150, Train: 1.5730, Valid: 1.3154, Test: 1.6782\n",
      "Epoch: 151, Train: 1.5812, Valid: 1.3163, Test: 1.6819\n",
      "Epoch: 152, Train: 1.5830, Valid: 1.3136, Test: 1.6812\n",
      "Epoch: 153, Train: 1.5881, Valid: 1.3161, Test: 1.6761\n",
      "Epoch: 154, Train: 1.5743, Valid: 1.3104, Test: 1.6774\n",
      "Epoch: 155, Train: 1.5779, Valid: 1.3152, Test: 1.6745\n",
      "Epoch: 156, Train: 1.5719, Valid: 1.3058, Test: 1.6693\n",
      "Epoch: 157, Train: 1.5790, Valid: 1.3074, Test: 1.6719\n",
      "Epoch: 158, Train: 1.5835, Valid: 1.3046, Test: 1.6722\n",
      "Epoch: 159, Train: 1.5834, Valid: 1.3044, Test: 1.6690\n",
      "Epoch: 160, Train: 1.5698, Valid: 1.3011, Test: 1.6709\n",
      "Epoch: 161, Train: 1.5673, Valid: 1.2935, Test: 1.6759\n",
      "Epoch: 162, Train: 1.5626, Valid: 1.3014, Test: 1.6768\n",
      "Epoch: 163, Train: 1.5705, Valid: 1.2951, Test: 1.6716\n",
      "Epoch: 164, Train: 1.5727, Valid: 1.3001, Test: 1.6631\n",
      "Epoch: 165, Train: 1.5757, Valid: 1.2985, Test: 1.6670\n",
      "Epoch: 166, Train: 1.5760, Valid: 1.2990, Test: 1.6690\n",
      "Epoch: 167, Train: 1.5723, Valid: 1.2963, Test: 1.6697\n",
      "Epoch: 168, Train: 1.5731, Valid: 1.2902, Test: 1.6784\n",
      "Epoch: 169, Train: 1.5704, Valid: 1.2962, Test: 1.6581\n",
      "Epoch: 170, Train: 1.5751, Valid: 1.2853, Test: 1.6691\n",
      "Epoch: 171, Train: 1.5700, Valid: 1.2915, Test: 1.6726\n",
      "Epoch: 172, Train: 1.5581, Valid: 1.2856, Test: 1.6698\n",
      "Epoch: 173, Train: 1.5692, Valid: 1.3000, Test: 1.6682\n",
      "Epoch: 174, Train: 1.5640, Valid: 1.2859, Test: 1.6666\n",
      "Epoch: 175, Train: 1.5635, Valid: 1.2838, Test: 1.6656\n",
      "Epoch: 176, Train: 1.5592, Valid: 1.2957, Test: 1.6692\n",
      "Epoch: 177, Train: 1.5601, Valid: 1.2856, Test: 1.6624\n",
      "Epoch: 178, Train: 1.5647, Valid: 1.2872, Test: 1.6623\n",
      "Epoch: 179, Train: 1.5710, Valid: 1.2893, Test: 1.6619\n",
      "Epoch: 180, Train: 1.5692, Valid: 1.2969, Test: 1.6628\n",
      "Epoch: 181, Train: 1.5602, Valid: 1.2868, Test: 1.6633\n",
      "Epoch: 182, Train: 1.5582, Valid: 1.2828, Test: 1.6589\n",
      "Epoch: 183, Train: 1.5594, Valid: 1.2889, Test: 1.6626\n",
      "Epoch: 184, Train: 1.5562, Valid: 1.2777, Test: 1.6621\n",
      "Epoch: 185, Train: 1.5715, Valid: 1.2837, Test: 1.6604\n",
      "Epoch: 186, Train: 1.5710, Valid: 1.2856, Test: 1.6559\n",
      "Epoch: 187, Train: 1.5613, Valid: 1.2856, Test: 1.6563\n",
      "Epoch: 188, Train: 1.5507, Valid: 1.2765, Test: 1.6597\n",
      "Epoch: 189, Train: 1.5583, Valid: 1.2766, Test: 1.6665\n",
      "Epoch: 190, Train: 1.5604, Valid: 1.2781, Test: 1.6537\n",
      "Epoch: 191, Train: 1.5620, Valid: 1.2774, Test: 1.6559\n",
      "Epoch: 192, Train: 1.5624, Valid: 1.2852, Test: 1.6552\n",
      "Epoch: 193, Train: 1.5511, Valid: 1.2727, Test: 1.6627\n",
      "Epoch: 194, Train: 1.5522, Valid: 1.2719, Test: 1.6633\n",
      "Epoch: 195, Train: 1.5637, Valid: 1.2762, Test: 1.6514\n",
      "Epoch: 196, Train: 1.5576, Valid: 1.2680, Test: 1.6587\n",
      "Epoch: 197, Train: 1.5558, Valid: 1.2732, Test: 1.6595\n",
      "Epoch: 198, Train: 1.5489, Valid: 1.2792, Test: 1.6538\n",
      "Epoch: 199, Train: 1.5515, Valid: 1.2730, Test: 1.6533\n"
     ]
    }
   ],
   "source": [
    "# Train the GCN using the CORA sample represented by `data` using the standard PyTorch training loop\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    train_loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    valid_loss = F.nll_loss(out[data.val_mask], data.y[data.val_mask])\n",
    "    test_loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask])\n",
    "    print(f'Epoch: {epoch:03d}, '\n",
    "      f'Train: {train_loss:.4f}, '\n",
    "      f'Valid: {valid_loss:.4f}, '\n",
    "      f'Test: {test_loss:.4f}')\n",
    "    valid_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.5795\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained GCN model on our test set\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f\"Test Set Accuracy: {acc:.4f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt with Full Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[169343, 128], edge_index=[2, 1166243], y=[169343], train_mask=[169343], val_mask=[169343], test_mask=[169343])\n",
      "there are 40 possible target classes\n",
      "GCN(\n",
      "  (conv1): GCNConv(128, 72)\n",
      "  (conv2): GCNConv(72, 40)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "raw_topology_df = gds.beta.graph.relationships.stream(g)\n",
    "\n",
    "raw_node_df = gds.graph.nodeProperties.stream(\n",
    "    g,\n",
    "    ['subjectId', 'year', 'textEmbedding'],\n",
    "    separate_property_columns=True,\n",
    ")\n",
    "\n",
    "node_df = raw_node_df.reset_index().rename(columns={'nodeId':'neo4jNodeId'}).rename(columns={'index':'nodeId'})\n",
    "\n",
    "topology_df = (raw_topology_df\n",
    "    .merge(node_df[['neo4jNodeId','nodeId']], how='left', left_on='sourceNodeId', right_on='neo4jNodeId')\n",
    "    .drop(columns=['sourceNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'sourceNodeId'})\n",
    "    .merge(node_df[['neo4jNodeId','nodeId']], how='left', left_on='targetNodeId', right_on='neo4jNodeId')\n",
    "    .drop(columns=['targetNodeId', 'neo4jNodeId'])\n",
    "    .rename(columns={'nodeId':'targetNodeId'})\n",
    ")\n",
    "\n",
    "topology = topology_df.by_rel_type()\n",
    "\n",
    "edge_index = torch.tensor(topology['CITES'], dtype=torch.long)\n",
    "\n",
    "x = torch.tensor(np.stack(node_df['textEmbedding']), dtype=torch.float)\n",
    "y = torch.tensor(np.stack(node_df['subjectId']), dtype=torch.long)\n",
    "\n",
    "full_data = Data(x=x, y=y, edge_index=edge_index)\n",
    "full_data.train_mask = torch.tensor(np.stack(node_df.year < VALID_YEAR))\n",
    "full_data.val_mask = torch.tensor(np.stack(node_df.year == VALID_YEAR))\n",
    "full_data.test_mask = torch.tensor(np.stack(node_df.year > VALID_YEAR))\n",
    "print(full_data)\n",
    "\n",
    "num_classes = y.unique().shape[0]\n",
    "print(f'there are {num_classes} possible target classes')\n",
    "\n",
    "full_model = GCN().to(device)\n",
    "print(full_model)\n",
    "\n",
    "full_data = full_data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(full_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "full_model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = full_model(full_data)\n",
    "    train_loss = F.nll_loss(out[full_data.train_mask], full_data.y[full_data.train_mask])\n",
    "    valid_loss = F.nll_loss(out[full_data.val_mask], full_data.y[full_data.val_mask])\n",
    "    test_loss = F.nll_loss(out[full_data.test_mask], full_data.y[full_data.test_mask])\n",
    "    #print(f'Epoch: {epoch:03d}, '\n",
    "    #  f'Train: {train_loss:.4f}, '\n",
    "    #  f'Valid: {valid_loss:.4f}, '\n",
    "    #  f'Test: {test_loss:.4f}')\n",
    "    valid_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.5597\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the full data trained GCN model on our test set\n",
    "full_model.eval()\n",
    "pred = full_model(full_data).argmax(dim=1)\n",
    "correct = (pred[full_data.test_mask] == full_data.y[full_data.test_mask]).sum()\n",
    "acc = int(correct) / int(full_data.test_mask.sum())\n",
    "\n",
    "print(f\"Test Set Accuracy: {acc:.4f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Remove Neo4j graph projections to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graphName                                                             proj\n",
       "database                                                             neo4j\n",
       "memoryUsage                                                               \n",
       "sizeInBytes                                                             -1\n",
       "nodeCount                                                           169343\n",
       "relationshipCount                                                  1166243\n",
       "configuration                                                           {}\n",
       "density                                                           0.000041\n",
       "creationTime                           2023-03-12T23:45:44.421389770+00:00\n",
       "modificationTime                       2023-03-12T23:45:45.729357467+00:00\n",
       "schema                   {'graphProperties': {}, 'relationships': {'CIT...\n",
       "schemaWithOrientation    {'graphProperties': {}, 'relationships': {'CIT...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_sample.drop()\n",
    "g.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
