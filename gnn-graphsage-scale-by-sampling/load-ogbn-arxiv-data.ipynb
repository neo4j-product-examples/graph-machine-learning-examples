{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load [`ogbn-arxiv`](https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv) Graph Into Neo4j (~5 Min)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ogb in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (1.3.4)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (1.21.5)\r\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (1.26.9)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (1.16.0)\r\n",
      "Requirement already satisfied: outdated>=0.2.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (0.2.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (1.0.2)\r\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (4.64.0)\r\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (1.4.2)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from ogb) (1.12.1)\r\n",
      "Requirement already satisfied: littleutils in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from outdated>=0.2.0->ogb) (0.2.2)\r\n",
      "Requirement already satisfied: requests in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from outdated>=0.2.0->ogb) (2.27.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2021.3)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (1.7.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (2.2.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (4.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zachblumenfeld/opt/anaconda3/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (2022.5.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ogb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "# Download and process data at './dataset/ogbg_molhiv/'\n",
    "dataset = NodePropPredDataset(name = \"ogbn-arxiv\", root = 'dataset/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "graph, subject = dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "        paperId                                      wordEmbedding\n0             0  [-0.05794300138950348, -0.05253000184893608, -...\n1             1  [-0.12449999898672104, -0.07066500186920166, -...\n2             2  [-0.08024200052022934, -0.02332800067961216, -...\n3             3  [-0.1450439989566803, 0.05491499975323677, -0....\n4             4  [-0.07115399837493896, 0.07076600193977356, -0...\n...         ...                                                ...\n169338   169338  [-0.32135099172592163, -0.03933500126004219, -...\n169339   169339  [-0.15121200680732727, -0.12470199912786484, -...\n169340   169340  [-0.22053000330924988, -0.03656800091266632, -...\n169341   169341  [-0.13823600113391876, 0.04088500142097473, -0...\n169342   169342  [-0.029874999076128006, 0.26841700077056885, -...\n\n[169343 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paperId</th>\n      <th>wordEmbedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[-0.05794300138950348, -0.05253000184893608, -...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[-0.12449999898672104, -0.07066500186920166, -...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[-0.08024200052022934, -0.02332800067961216, -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[-0.1450439989566803, 0.05491499975323677, -0....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[-0.07115399837493896, 0.07076600193977356, -0...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>169338</th>\n      <td>169338</td>\n      <td>[-0.32135099172592163, -0.03933500126004219, -...</td>\n    </tr>\n    <tr>\n      <th>169339</th>\n      <td>169339</td>\n      <td>[-0.15121200680732727, -0.12470199912786484, -...</td>\n    </tr>\n    <tr>\n      <th>169340</th>\n      <td>169340</td>\n      <td>[-0.22053000330924988, -0.03656800091266632, -...</td>\n    </tr>\n    <tr>\n      <th>169341</th>\n      <td>169341</td>\n      <td>[-0.13823600113391876, 0.04088500142097473, -0...</td>\n    </tr>\n    <tr>\n      <th>169342</th>\n      <td>169342</td>\n      <td>[-0.029874999076128006, 0.26841700077056885, -...</td>\n    </tr>\n  </tbody>\n</table>\n<p>169343 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw_node_df = pd.DataFrame(graph['node_feat'])\n",
    "\n",
    "raw_node_df['wordEmbedding'] = raw_node_df.apply(lambda x: x.tolist(), axis=1)\n",
    "node_df = raw_node_df[['wordEmbedding']].reset_index().rename(columns={'index': 'paperId'})\n",
    "node_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "node_df['year'] = graph['node_year']\n",
    "node_df['subject'] = subject"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "split_index = dataset.get_idx_split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "node_df['split'] = -1\n",
    "node_df['splitName'] = 'UNKNOWN'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "node_df.loc[split_index['train'], 'split'] = 0\n",
    "node_df.loc[split_index['train'], 'splitName'] = 'TRAIN'\n",
    "\n",
    "node_df.loc[split_index['valid'], 'split'] = 1\n",
    "node_df.loc[split_index['valid'], 'splitName'] = 'VALID'\n",
    "\n",
    "node_df.loc[split_index['test'], 'split'] = 2\n",
    "node_df.loc[split_index['test'], 'splitName'] = 'TEST'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                   cnt\nsplit splitName       \n0     TRAIN      90941\n1     VALID      29799\n2     TEST       48603",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>cnt</th>\n    </tr>\n    <tr>\n      <th>split</th>\n      <th>splitName</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <th>TRAIN</th>\n      <td>90941</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <th>VALID</th>\n      <td>29799</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <th>TEST</th>\n      <td>48603</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df[['split', 'splitName', 'paperId']].groupby(['split', 'splitName']).agg('count').rename(columns={'paperId': 'cnt'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "         paperId  citedPaperId\n0         104447         13091\n1          15858         47283\n2         107156         69161\n3         107156        136440\n4         107156        107366\n...          ...           ...\n1166238    45118         79124\n1166239    45118        147994\n1166240    45118        162473\n1166241    45118        162537\n1166242    45118         72717\n\n[1166243 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paperId</th>\n      <th>citedPaperId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>104447</td>\n      <td>13091</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15858</td>\n      <td>47283</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>107156</td>\n      <td>69161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>107156</td>\n      <td>136440</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>107156</td>\n      <td>107366</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1166238</th>\n      <td>45118</td>\n      <td>79124</td>\n    </tr>\n    <tr>\n      <th>1166239</th>\n      <td>45118</td>\n      <td>147994</td>\n    </tr>\n    <tr>\n      <th>1166240</th>\n      <td>45118</td>\n      <td>162473</td>\n    </tr>\n    <tr>\n      <th>1166241</th>\n      <td>45118</td>\n      <td>162537</td>\n    </tr>\n    <tr>\n      <th>1166242</th>\n      <td>45118</td>\n      <td>72717</td>\n    </tr>\n  </tbody>\n</table>\n<p>1166243 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = pd.DataFrame(graph['edge_index'].T)\n",
    "edge_df.columns = ['paperId', 'citedPaperId']\n",
    "edge_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import json\n",
    "with open('secrets.json') as f:\n",
    "    secrets = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "# Use Neo4j URI and credentials according to your setup\n",
    "gds = GraphDataScience(secrets['host'], auth=(secrets['username'], secrets['password']), aura_ds=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [label, key, keys, unique, action]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>key</th>\n      <th>keys</th>\n      <th>unique</th>\n      <th>action</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear last graph - All data and schema attributes\n",
    "gds.run_cypher('MATCH(n) DETACH DELETE n')\n",
    "gds.run_cypher('CALL apoc.schema.assert({},{})')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.run_cypher('CREATE CONSTRAINT paper_unique IF NOT EXISTS ON (n:Paper) ASSERT n.paperId  IS UNIQUE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df_chunks = []\n",
    "i=0\n",
    "while i<node_df.shape[0]:\n",
    "    next_i = i + 10_000\n",
    "    node_df_chunks.append(node_df[i:next_i])\n",
    "    i = next_i\n",
    "len(node_df_chunks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(n)\n",
      "0     10000\n",
      "Ingested 1 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 2 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 3 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 4 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 5 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 6 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 7 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 8 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 9 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 10 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 11 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 12 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 13 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 14 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 15 of 17 chunks\n",
      "   count(n)\n",
      "0     10000\n",
      "Ingested 16 of 17 chunks\n",
      "   count(n)\n",
      "0      9343\n",
      "Ingested 17 of 17 chunks\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for node_df_chunk in node_df_chunks:\n",
    "    i+=1\n",
    "    node_records = node_df_chunk.to_dict('records')\n",
    "    print(gds.run_cypher('''\n",
    "        UNWIND $nodeRecords AS nodeRecord\n",
    "        WITH toInteger(nodeRecord.paperId) AS paperId,\n",
    "            toFloatList(nodeRecord.wordEmbedding) AS wordEmbedding,\n",
    "            toInteger(nodeRecord.year) AS year,\n",
    "            toInteger(nodeRecord.subject) AS subject,\n",
    "            toInteger(nodeRecord.split) AS split,\n",
    "            nodeRecord.splitName AS splitName\n",
    "        MERGE(n:Paper {paperId: paperId})\n",
    "        SET n.wordEmbedding=wordEmbedding,\n",
    "            n.year=year,\n",
    "            n.subject=subject,\n",
    "            n.split=split,\n",
    "            n.splitName=splitName\n",
    "        RETURN count(n)\n",
    "    ''', params={'nodeRecords':node_records}))\n",
    "    print(f'Ingested {i} of {len(node_df_chunks)} chunks')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.run_cypher('''\n",
    "    MATCH (n:Paper) WHERE n.split=0\n",
    "    SET n:TrainPaper\n",
    "''')\n",
    "\n",
    "gds.run_cypher('''\n",
    "    MATCH (n:Paper) WHERE n.split=1\n",
    "    SET n:ValidPaper\n",
    "''')\n",
    "\n",
    "gds.run_cypher('''\n",
    "    MATCH (n:Paper) WHERE n.split=2\n",
    "    SET n:TestPaper\n",
    "''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df_chunks = []\n",
    "i=0\n",
    "while i<edge_df.shape[0]:\n",
    "    next_i = i + 150_000\n",
    "    edge_df_chunks.append(edge_df[i:next_i])\n",
    "    i = next_i\n",
    "len(edge_df_chunks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(r)\n",
      "0    150000\n",
      "Ingested 1 of 8 chunks\n",
      "   count(r)\n",
      "0    150000\n",
      "Ingested 2 of 8 chunks\n",
      "   count(r)\n",
      "0    150000\n",
      "Ingested 3 of 8 chunks\n",
      "   count(r)\n",
      "0    150000\n",
      "Ingested 4 of 8 chunks\n",
      "   count(r)\n",
      "0    150000\n",
      "Ingested 5 of 8 chunks\n",
      "   count(r)\n",
      "0    150000\n",
      "Ingested 6 of 8 chunks\n",
      "   count(r)\n",
      "0    150000\n",
      "Ingested 7 of 8 chunks\n",
      "   count(r)\n",
      "0    116243\n",
      "Ingested 8 of 8 chunks\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for edge_df_chunk in edge_df_chunks:\n",
    "    i+=1\n",
    "    edge_records = edge_df_chunk.to_dict('records')\n",
    "    print(gds.run_cypher('''\n",
    "        UNWIND $edgeRecords AS edgeRecord\n",
    "        WITH toInteger(edgeRecord.paperId) AS paperId,\n",
    "            toInteger(edgeRecord.citedPaperId) AS citedPaperId\n",
    "        MATCH(n0:Paper {paperId: paperId})\n",
    "        MATCH(n1:Paper {paperId: citedPaperId})\n",
    "        MERGE (n0)-[r:CITED]->(n1)\n",
    "        RETURN count(r)\n",
    "    ''', params={'edgeRecords':edge_records}))\n",
    "    print(f'Ingested {i} of {len(edge_df_chunks)} chunks')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
